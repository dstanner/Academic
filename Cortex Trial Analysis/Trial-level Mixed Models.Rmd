---
title: "Trial-level mixed models analysis for 'Robust neurocognitive individual differences in grammatical agreement processing: A latent variable approach'"
author: "Darren Tanner"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

# Prep data

```{r}
library(dplyr)
library(tidyr)
library(magrittr)
library(lme4)
library(emmeans)


# Load full datasets exported from matlab
N4_data <- read.csv("./Datafiles/N4_trial_amplitudes.csv")
P6_data <- read.csv("./Datafiles/P6_trial_amplitudes.csv")


# Due to an RA error, ppt 138 had a second task recorded with their experiment
# EEG recording, which resulted in 5 extra events from the second task getting 
# included with the bin labels for this task; this was fixed elsewise in the standard
# ERP analysis. Here we exclude the last five observations from that ppt's data
p138_N4 <- N4_data[N4_data$Subject == 138, ]
N4_data <- N4_data[N4_data$Subject != 138, ]
p138_N4 <- p138_N4[-c(121:125),]
N4_data <- rbind(N4_data, p138_N4)
rm(p138_N4)

p138_P6 <- P6_data[P6_data$Subject == 138, ]
P6_data <- P6_data[P6_data$Subject != 138, ]
p138_P6 <- p138_P6[-c(121:125), ]
P6_data <- rbind(P6_data, p138_P6)
rm(p138_P6)


# Subset to non-rejected trials
N4_data <- subset(N4_data, Rejected == 0)
P6_data <- subset(P6_data, Rejected == 0)


# Subset to the electrodes we want
keep_cols <- unlist(strsplit("C3 Cz C4 CP1 CP2 P3 Pz P4 Index Epoch Bin Subject", split = " "))

N4_data <- N4_data[keep_cols]
P6_data <- P6_data[keep_cols]
rm(keep_cols)


# Make columns for fixed factors
N4_data$Grammaticality <- ifelse(N4_data$Bin %in% c(1, 3), "Gram", "Ungram")
P6_data$Grammaticality <- ifelse(P6_data$Bin %in% c(1, 3), "Gram", "Ungram")

N4_data$VerbType <- ifelse(N4_data$Bin %in% c(1, 2), "Aux", "Lex")
P6_data$VerbType <- ifelse(P6_data$Bin %in% c(1, 2), "Aux", "Lex")

# Get item numbers from output of Item/event processing scripts
item_info_RSVP <- read.csv("./Datafiles/Trial_Item_information_RSVP.csv")
item_info_SPR <- read.csv("./Datafiles/Trial_Item_Information_SPR.csv")
items_df <- rbind(item_info_RSVP, item_info_SPR)
N4_data <- left_join(N4_data, select(items_df, -c(PrecritCode, Event_code)), by = c("Subject", "Index", "Bin"))
P6_data <- left_join(P6_data, select(items_df, -c(PrecritCode, Event_code)), by = c("Subject", "Index", "Bin"))
rm(item_info_RSVP,item_info_SPR,items_df)


# Convert to long
N4_data <- gather(N4_data, "Elec", "Amplitude", -c(9:15))
P6_data <- gather(P6_data, "Elec", "Amplitude", -c(9:15))

# Get Individual Differences Data
ID_data <- read.csv("./Datafiles/IndividualDifferences_with_scores.csv")
N4_data <- left_join(N4_data, select(ID_data, -c(2:6)), by = c("Subject" = "ParticipantID"))
P6_data <- left_join(P6_data, select(ID_data, -c(2:6)), by = c("Subject" = "ParticipantID"))
rm(ID_data)

# Make sure the RC measures from the PCA are truly scaled and centered:
N4_data[,c("RC1", "RC2")] <- apply(N4_data[,c("RC1", "RC2")], 2,  scale)
P6_data[,c("RC1", "RC2")] <- apply(P6_data[,c("RC1", "RC2")], 2, scale)

# Assign categorical variables to sum-coded factors.
factor_sum_code <- function(vec, high_factor_level, num_levels = length(unique(vec))){
  vec <- factor(vec)
  vec <- relevel(vec, ref = high_factor_level)
  contrasts(vec) <- contr.sum(num_levels)
  return(vec)
}

N4_data$Grammaticality <- factor_sum_code(N4_data$Grammaticality, "Ungram")
N4_data$VerbType <- factor_sum_code(N4_data$VerbType, "Lex")
P6_data$Grammaticality <- factor_sum_code(P6_data$Grammaticality, "Ungram")
P6_data$VerbType <- factor_sum_code(P6_data$VerbType, "Lex")

# Collapse across electrodes
collapsed_N4_data <- N4_data %>%
  group_by(Subject, Grammaticality, VerbType, Item) %>%
  summarize(
    Amplitude = mean(Amplitude),
    RC1 = mean(RC1), 
    RC2 = mean(RC2)
  ) %>% ungroup() %>% as.data.frame()

collapsed_P6_data <- P6_data %>%
  group_by(Subject, Grammaticality, VerbType, Item) %>%
  summarize(
    Amplitude = mean(Amplitude),
    RC1 = mean(RC1), 
    RC2 = mean(RC2)
  ) %>% ungroup() %>% as.data.frame()



```

# Fit mixed models in each time window

```{r}
## The lines for fitting the models are commented out to 
## save run time when knitting the html output.
## 
## The model objects are loaded and summaries displayed.


# Fit maximal model to P6 data
# P6_mod <- lmer(Amplitude ~ Grammaticality*VerbType*RC1*RC2 +
#                   (Grammaticality*VerbType|Subject) +
#                   (Grammaticality*VerbType|Item), collapsed_P6_data)
# saveRDS(P6_mod, "P6_mod.rds")
P6_mod <- readRDS("./Model Objects/P6_mod.rds")
summary(P6_mod)



# Fit maximal model to N4 data
# N4_mod <- lmer(Amplitude ~ Grammaticality*VerbType*RC1*RC2 +
#                   (Grammaticality*VerbType|Subject) +
#                   (Grammaticality*VerbType|Item), collapsed_N4_data)
# saveRDS(N4_mod, "N4_mod.rds")
N4_mod <- readRDS("./Model Objects/N4_mod.rds")
summary(N4_mod)
## Remove the random slope for Grammaticality by item, because of extremely
## low variance estimate


# Fit reduced N4 models
# N4_mod2 <- lmer(Amplitude ~ Grammaticality*VerbType*RC1*RC2 +
#                   (Grammaticality*VerbType|Subject) +
#                   (VerbType + Grammaticality:VerbType|Item), collapsed_N4_data)
# saveRDS(N4_mod2, "N4_mod2.rds")
N4_mod2 <- readRDS("./Model Objects/N4_mod2.rds")
summary(N4_mod2)


```

